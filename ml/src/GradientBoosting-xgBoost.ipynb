{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting (xgBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting** with xgBoost. **xgBoost** is one of the most popular gradient boosting library in public domain.\n",
    "**xgBoost** added some novel innovations to Gradient boosting that make it very successful. Some of those innovations are listed below:\n",
    "1. A new regularized learning objective \n",
    "\n",
    "    $\\mathcal{L} = \\sum_{i}l(\\hat{y}_i,y_i) + \\sum_k\\Omega(f_k)$, where $\\Omega(f) = \\gamma T + \\frac{1}{2}\\lambda ||w||^2$\n",
    "\n",
    "2. Weighted approximate histogram based split finding. **xgBoost** has a mode to do approximate splitting of the tree based on an histogram. For exact splitting of a node the time complexity is $\\mathcal{O}(n \\text{ log}(n)\\text{ }m)$ where $m$ is the number of features and $n$ is the number of samples and for histogram bases splitting the complexity is $\\mathcal{O}(n\\text{}m)$ for histogram building and $\\mathcal{O}(b \\text{}m)$ for split point finding where $b$ is the number of bins.\n",
    "\n",
    "3. Sparsity aware split finding. What **xgBoost** does is for every node there is a default split direction, that is the direction which leads to maximum reduction in loss. If the data in missing then that default direction is picked.\n",
    "\n",
    "4. Parallel and distributed computing. And out-of-core training of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Make the sheet width 100%\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load adults dataset**\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "colnames = ['age', 'workclass', 'fnlwgt', 'education', \n",
    "            'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "           'race', 'sex', 'capital-gain','capital-loss', 'hours-per-week', \n",
    "           'native-country', 'target']\n",
    "df_adult_train=pd.read_csv(\"../data/adults/adult.data\",header=None, names=colnames)\n",
    "df_adult_test=pd.read_csv(\"../data/adults/adult.test\",header=None, names=colnames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing data\n",
    "df_adult_train.replace(' ?' , np.nan, inplace=True)\n",
    "df_adult_test.replace(' ?' , np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one hot encoding to categorical columns\n",
    "cat_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'native-country']\n",
    "def applyOneHot(df, cat_columns):\n",
    "    onehot_df = df[cat_columns]\n",
    "    onehot_df = pd.get_dummies(onehot_df, columns = cat_columns)\n",
    "    onehot_drop = df.drop(cat_columns, axis = 1)\n",
    "    df = pd.concat([onehot_drop, onehot_df], axis = 1)\n",
    "    return df\n",
    "\n",
    "df_adult_train = applyOneHot(df_adult_train, cat_columns)\n",
    "df_adult_test = applyOneHot(df_adult_test, cat_columns)\n",
    "#There is no data point with native-country_ Holand-Netherlands in test set lets add that zero column\n",
    "df_adult_test['native-country_ Holand-Netherlands'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is an extra . in test labels remove that\n",
    "df_adult_test.replace(to_replace={r' <=50K.': ' <=50K',r' >50K.':' >50K'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Label encoder to y\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le = le.fit(df_adult_train['target'])\n",
    "df_adult_train['target'] = le.transform(df_adult_train['target'])\n",
    "df_adult_test['target'] = le.transform(df_adult_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult_test['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set = 16281\n",
      "Size of train set = 32561\n"
     ]
    }
   ],
   "source": [
    "#Make X_train, X_test, y_train, y_test\n",
    "X_train = df_adult_train.drop('target', axis=1).values.astype('float')\n",
    "y_train = df_adult_train['target'].values.astype('float')\n",
    "X_test = df_adult_test.drop('target', axis=1).values.astype('float')\n",
    "y_test = df_adult_test['target'].values.astype('float')\n",
    "\n",
    "assert y_test.shape[0] == X_test.shape[0]\n",
    "assert y_train.shape[0] == X_train.shape[0]\n",
    "\n",
    "print(f\"Size of test set = {y_test.shape[0]}\")\n",
    "print(f\"Size of train set = {y_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets standardize the Xs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.853\n",
      "Test score=0.845\n"
     ]
    }
   ],
   "source": [
    "#Lets first apply Logistics regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=500)\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression has decent test score of 84.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=1.0\n",
      "Test score=0.797\n"
     ]
    }
   ],
   "source": [
    "#Lets fit a single decision tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=2)\n",
    "clf = clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree has very good train score but bad test score. It seems like it has overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=1.0\n",
      "Test score=0.86\n"
     ]
    }
   ],
   "source": [
    "#Now lets fit random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=500, min_samples_split=2)\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest seems to be over-fitting also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.9\n",
      "Test score=0.872\n"
     ]
    }
   ],
   "source": [
    "#Lets use default XgBoost parameters\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgBoost default parameters giving very good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fef1bec3c90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets plot feature importance\n",
    "plt.figure(figsize=(20,20))\n",
    "xgb.plot_importance(clf, max_num_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets search parameters of xgBoost to see if we can improve on the default parameters\n",
    "Some important parameters to search on are \n",
    "1. max_depth of each tree \n",
    "2. gamma - Regularization penalty for splitting one more level.\n",
    "3. eta - learning rate\n",
    "4. Lambda - L2 regularization term on weights\n",
    "5. Boosting steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 0,\n",
       " 'num_parallel_tree': 1,\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.874\n",
      "{'gamma': 2, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'learning_rate' : [ 0.1, 1],\n",
    "        'gamma': [0, 1, 2, 10],\n",
    "        'max_depth': [5, 6, 10],\n",
    "        'reg_lambda': [0.01, 0.1, 1, 2],\n",
    "        'n_estimators': [100, 500, 1000]\n",
    "        }\n",
    "clf = xgb.XGBClassifier(tree_method='hist')\n",
    "gs = GridSearchCV(clf, \n",
    "                    param_grid=params, \n",
    "                    scoring='accuracy',  \n",
    "                    cv=5,\n",
    "                    n_jobs=1)\n",
    "gs = gs.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"Best score = {gs.best_score_:.3}\")\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.889\n",
      "Test score=0.874\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(tree_method='hist', \n",
    "                        gamma=2,\n",
    "                        learning_rate=0.1,\n",
    "                        max_depth=6,\n",
    "                        n_estimators=500,\n",
    "                        reg_lambda=1)\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One important feature of xgBoost is histogram and approx searches below we will compare the speed advantage of histogram or exact search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "Train score=0.9\n",
      "Test score=0.872\n",
      "10.8 s ± 145 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#Exact search\n",
    "clf = xgb.XGBClassifier(tree_method='exact')\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "Train score=0.901\n",
      "Test score=0.866\n",
      "10.7 s ± 124 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#Approx search\n",
    "clf = xgb.XGBClassifier(tree_method='approx')\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "Train score=0.9\n",
      "Test score=0.87\n",
      "902 ms ± 41.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#Hist search\n",
    "clf = xgb.XGBClassifier(tree_method='hist')\n",
    "clf.fit(X_train_std, y_train)\n",
    "print(f\"Train score={clf.score(X_train_std, y_train):.3}\")\n",
    "print(f\"Test score={clf.score(X_test_std, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that there is not much difference between exact and approx. But hist is **10x** faster than either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the difference between hist and approx?\n",
    "Approximate splitting method in **xgBoost** buckets continuous features into discrete bins to speed up training. The approx method generates a new set of bins for each iteration, whereas the hist method re-uses the bins over multiple iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
