{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-russian",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Methods\" data-toc-modified-id=\"Methods-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#DBSCAN\" data-toc-modified-id=\"DBSCAN-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>DBSCAN</a></span></li><li><span><a href=\"#One-Class-SVM\" data-toc-modified-id=\"One-Class-SVM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>One Class SVM</a></span></li><li><span><a href=\"#Isolation-Forest\" data-toc-modified-id=\"Isolation-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Isolation Forest</a></span></li><li><span><a href=\"#AutoEncoders\" data-toc-modified-id=\"AutoEncoders-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>AutoEncoders</a></span></li><li><span><a href=\"#GANomaly\" data-toc-modified-id=\"GANomaly-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>GANomaly</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-spare",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-portfolio",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Anomaly detection** is an important problem in machine\n",
    "learning and has a wide range of applications such as fraud\n",
    "detection, intrusion detection, event detection and health care (spotting a malignant tumor in an MRI scan). \n",
    "In most anomaly detection problems, a lot of normal data is given, and the task is to detect\n",
    "anomalies that deviates from the normal data. \n",
    "**Anomaly detection** algorithms model the data distribution and then report samples atypical in the distribution as anomalies.\n",
    "\n",
    "There are various **ML** algorithms which are used for **Anomaly Detection**, in the notebook below we will explore some of those **ML** algorithms. Its hard to find datasets for **Anomaly Detection** hence we will mixture of Fraud, synthetic and vision data.\n",
    "\n",
    "\n",
    "Some of the ML algorithms we will explore are:\n",
    "1. Density-Based Anomaly Detection method like, **DBSCAN**.\n",
    "2. Support Vector Machine-Based Anomaly Detection, **One Class SVM**.\n",
    "3. Decision tree-Based Anomaly Detection, **Isolation Forest**.\n",
    "4. Deep Neural Network-Based Anomaly Detection, **Autoencoders**.\n",
    "5. GANs-Bases Anomaly Detection, **GANomaly**.\n",
    "\n",
    "Some of the techniques like **DBSCAN** and **One Class SVM** are traditional **ML** techniques and others like **GANomaly** are cutting edge model deep learning techniques. Also there are many other methods which have been successfully applied to **Anomaly Detection** above list is a representative yet wide selection of methods in literature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-stylus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:47:28.906312Z",
     "start_time": "2021-03-28T20:47:28.897027Z"
    }
   },
   "source": [
    "## Methods\n",
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-detroit",
   "metadata": {},
   "source": [
    "**Density-based spatial clustering of applications with noise (DBSCAN)** is a very popular clustering algorithm proposed by Martin Ester et.al. \n",
    "https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf\n",
    "\n",
    "It is a density-based clustering algorithm: given a set of points, it groups together points that are closely packed together, marking as anomalous the points that lie alone in low-density regions. One advantage of **DBSCAN** over **KMeans** is it can identify non circular clusters too. Below we show an example of using **DBSCAN** to identify anomalies/outliers in synthetic data. One of the limitation of **DBSCN** is it struggles from **Curse of dimensionality**, as the data becomes more higher dimensional **DBSCAN** underperfoms. \n",
    "\n",
    "Below we create synthetic data to show application of **DBSCAN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-armstrong",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:34.233059Z",
     "start_time": "2021-03-29T20:57:31.033803Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-darwin",
   "metadata": {},
   "source": [
    "First we create synthetic data to show application of **DBSCAN**\n",
    "Data set is sampled from three **Gaussian** distributions centered at, (0,0), (1,1) and (0,1)\n",
    "And there are two outliers at (2,0) and (0,3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-roots",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:34.255331Z",
     "start_time": "2021-03-29T20:57:34.243300Z"
    }
   },
   "outputs": [],
   "source": [
    "n_points_per_cluster = 100\n",
    "\n",
    "#Cluster 1 at -> (0,0)\n",
    "C1 = [0, 0] + .1 * np.random.randn(n_points_per_cluster, 2)\n",
    "y1 = np.ones(shape=n_points_per_cluster)\n",
    "\n",
    "#Cluster 2 at -> (1,1)\n",
    "C2 = [1, 1] + .1 * np.random.randn(n_points_per_cluster, 2)\n",
    "y2 = np.ones(shape=n_points_per_cluster) + 1\n",
    "\n",
    "#Cluster 3 at -> (0,1)\n",
    "C3 = [0, 1] + .1 * np.random.randn(n_points_per_cluster, 2)\n",
    "y3 = np.ones(shape=n_points_per_cluster) + 2\n",
    "\n",
    "#Anomalies\n",
    "C4 = np.array([[2,0],[0,3]])\n",
    "y4 = [4,4]\n",
    "\n",
    "X = np.vstack((C1, C2, C3, C4))\n",
    "y = np.hstack((y1,y2,y3,y4))\n",
    "y= y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-facial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:34.656485Z",
     "start_time": "2021-03-29T20:57:34.261336Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Cluster plot')\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, palette='dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-billion",
   "metadata": {},
   "source": [
    "From the above plots we can see there are three clusters 1,2, and 3 and then there are two outliers at (0,2) and (3,0). Now we will apply **DBSCAN** to identify these clusters and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-command",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:34.666063Z",
     "start_time": "2021-03-29T20:57:34.660903Z"
    }
   },
   "outputs": [],
   "source": [
    "#We initialize DBScan with epsilon of 0.2 and min_samples of 10\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-screw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:34.678481Z",
     "start_time": "2021-03-29T20:57:34.669317Z"
    }
   },
   "outputs": [],
   "source": [
    "y_dbscan = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-thong",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:35.148712Z",
     "start_time": "2021-03-29T20:57:34.690430Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y_dbscan, palette='dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-halifax",
   "metadata": {},
   "source": [
    "We can see from the plot above **DBSCAN** correctly identified the three clusters 0,1, and 2. \n",
    "And also identified the two outliers with -1.\n",
    "\n",
    "This is a toy example but should illustrate the application of **DBSCAN**. Other popular variation of **DBSCAN** is **OPTICS** algorithm that algorithm can also identify clusters of very different densities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-outside",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T21:34:51.459379Z",
     "start_time": "2021-03-28T21:34:51.454464Z"
    }
   },
   "source": [
    "### One Class SVM\n",
    "\n",
    "Second ML method we want to discuss is **OneClassSVM**. **OneClassSVM** is an unsupervised learning algorithm that is trained only on the \"normal\" data. It learns the boundaries of normal data and classifies anything which is not inside the boundary as anomalous.\n",
    "\n",
    "\n",
    "Method was originally proposed in this paper, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.575&rep=rep1&type=pdf. Its still a fairly popular method for Anomaly detection especially when datasets are not that large.\n",
    "\n",
    "\n",
    "Below we will demonstrate the use of **One Class SVM** on credit card fraud dataset from Kaggle https://www.kaggle.com/mlg-ulb/creditcardfraud.\n",
    "\n",
    "There are 492 cases of fraud out of 284,807 transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-singing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:40.745263Z",
     "start_time": "2021-03-29T20:57:38.006440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets load the data\n",
    "data = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-mouth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:40.801131Z",
     "start_time": "2021-03-29T20:57:40.747903Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets look at the head of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-immune",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:40.868155Z",
     "start_time": "2021-03-29T20:57:40.806029Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-tongue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T14:58:23.009979Z",
     "start_time": "2021-03-29T14:58:22.982805Z"
    }
   },
   "source": [
    "Data has 31 columns, we will drop the Time columns and Class column has tag fraud or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-favorite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:44.694325Z",
     "start_time": "2021-03-29T20:57:44.635002Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(['Time'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-librarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:57:44.772858Z",
     "start_time": "2021-03-29T20:57:44.755245Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets look a the distribution of normal and anomalous data\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-packet",
   "metadata": {},
   "source": [
    "Lets use the data to create a train, dev, and test dataset split.\n",
    "For train we will take 80% of the normal data.\n",
    "For dev we will take 10% of the normal data and 50% of anomalous data.\n",
    "For test we will take 10% of the normal data and 50% of anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-jackson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:58:08.468936Z",
     "start_time": "2021-03-29T20:58:08.373994Z"
    }
   },
   "outputs": [],
   "source": [
    "data_normal = data[data['Class']==0]\n",
    "data_anomalous = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-scholarship",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:58:08.554274Z",
     "start_time": "2021-03-29T20:58:08.474484Z"
    }
   },
   "outputs": [],
   "source": [
    "X_normal = data_normal.drop(['Class'], axis=1).values\n",
    "#Lets downsample the X_normal data so that we can compute quickly\n",
    "number_of_rows=20000\n",
    "ran_rows = np.random.choice(X_normal.shape[0], size=number_of_rows, replace=False, )\n",
    "X_normal = X_normal[ran_rows,:]\n",
    "X_anomalous = data_anomalous.drop(['Class'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-expert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:09:47.199519Z",
     "start_time": "2021-03-29T22:09:47.183490Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_nm_train, X_nm_test_dev = train_test_split(X_normal, train_size=0.8)\n",
    "X_nm_test, X_nm_dev = train_test_split(X_nm_test_dev, train_size=0.5)\n",
    "X_a_test, X_a_dev = train_test_split(X_anomalous, train_size=0.5)\n",
    "#Train set only has normal samples\n",
    "X_train = X_nm_train\n",
    "#Dev set has 10% of Normal samples and 50% of anomalous samples\n",
    "X_dev = np.vstack([X_nm_dev, X_a_dev])\n",
    "y_dev = np.vstack([np.full(shape=(X_nm_dev.shape[0],1), dtype='int',fill_value=1), \n",
    "                   np.full(shape=(X_a_dev.shape[0],1), dtype='int',fill_value=-1)])\n",
    "#Test set has 10% of Normal samples and 50% of anomalous samples\n",
    "X_test = np.vstack([X_nm_test, X_a_test])\n",
    "y_test = np.vstack([np.full(shape=(X_nm_test.shape[0],1),dtype='int',fill_value=1),\n",
    "                    np.full(shape=(X_a_test.shape[0],1), dtype='int',fill_value=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-substance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:09.653677Z",
     "start_time": "2021-03-29T22:11:09.645252Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train set shape={X_train.shape}\")\n",
    "print(f\"Dev set shape={X_dev.shape}\")\n",
    "print(f\"Test set shape={X_test.shape}\")\n",
    "print(f\"Anomalies in Dev Set={np.sum(y_dev==-1)}\")\n",
    "print(f\"Anomalies in Test Set={np.sum(y_test==-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-spain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:16.519851Z",
     "start_time": "2021-03-29T22:11:16.497697Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now lets normalize X data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_dev_std = sc.transform(X_dev)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-migration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:36.578380Z",
     "start_time": "2021-03-29T22:11:17.332146Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets train oneclass SVM with default parameters\n",
    "from sklearn.svm import OneClassSVM\n",
    "clf = OneClassSVM().fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-memory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:41.904244Z",
     "start_time": "2021-03-29T22:11:36.582011Z"
    }
   },
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev_std)\n",
    "y_test_pred = clf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-statement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:45.604551Z",
     "start_time": "2021-03-29T22:11:45.588531Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets look at confusion matrix \n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "cm = confusion_matrix(y_dev, y_dev_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-greek",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:11:52.126402Z",
     "start_time": "2021-03-29T22:11:52.111545Z"
    }
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-baghdad",
   "metadata": {},
   "source": [
    "Not very good performance. Lets use hold out CV to tune some parameters of OneClassSVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-atlanta",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:59:47.432797Z",
     "start_time": "2021-03-29T22:53:52.565866Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let write a simple CV loop to find good hyper parameters for OneClassSVM\n",
    "gammas = np.logspace(-4,0,5)\n",
    "nus = np.linspace(0.01,0.1,5)\n",
    "for g in gammas:\n",
    "    for nu in nus:\n",
    "        clf = OneClassSVM(gamma=g, nu=nu)\n",
    "        clf.fit(X_train_std)\n",
    "        y_dev_pred = clf.predict(X_dev_std)\n",
    "        print(f\"gamma={g:.2}, nu = {nu:.2}, CV score = {f1_score(y_dev,y_dev_pred, pos_label=-1):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-qualification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:59:48.044619Z",
     "start_time": "2021-03-29T22:59:47.436554Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets fit the best classifier\n",
    "clf = OneClassSVM(gamma=0.01, nu=0.01)\n",
    "clf.fit(X_train_std)\n",
    "y_dev_pred = clf.predict(X_dev_std)\n",
    "cm = confusion_matrix(y_dev, y_dev_pred)\n",
    "print(cm)\n",
    "print(f\"Dev F1 Score = {f1_score(y_dev,y_dev_pred, pos_label=-1):0.3}\")\n",
    "\n",
    "#Lets also check the test set\n",
    "y_test_pred = clf.predict(X_test_std)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "print(f\"Test F1 Score = {f1_score(y_test,y_test_pred, pos_label=-1):0.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-treasury",
   "metadata": {},
   "source": [
    "We can see from the results that we have a very high F1 score in test and dev set.\n",
    "In test set algorithm is able to identify 199 out of 246 anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-strand",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-species",
   "metadata": {},
   "source": [
    "**Isolation Forest** is one of the most successful method for Anomaly/outlier detection. **Isolation Forest** was first proposed in this paper\n",
    "https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolation-forest\n",
    "\n",
    "In **Isolation Forest** algorithm, anomalies are explicitly isolated. The algorithm works by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.\n",
    "\n",
    "Authors of the algorithm made an observation that since anomalies are so different from normal data they will have less depth in the tree then normal data points. Based on this observation and also on the depth of data points in the tree authors came up with an anomaly score to rank each data point as anomalous or normal.\n",
    "\n",
    "An anomaly score of 1 indicates surely an anomaly and an anomaly score of 0 indicates surely a normal data point.\n",
    "\n",
    "Below in the notebook we will use **KDDCup99 (SMTP)** dataset \n",
    "\n",
    "https://scikit-learn.org/0.19/modules/generated/sklearn.datasets.fetch_kddcup99.html\n",
    "\n",
    "This dataset was initially created by DARPA to detect intrusion of their systems and is a standard dataset used for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-courage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:32:41.139134Z",
     "start_time": "2021-03-30T01:31:41.029803Z"
    }
   },
   "outputs": [],
   "source": [
    "#Download KDDCup99 (SMTP) data \n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "data = fetch_kddcup99(subset='smtp', as_frame=True, percent10=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-requirement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:32:50.274733Z",
     "start_time": "2021-03-30T01:32:50.270496Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data['frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-banks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:32:58.790028Z",
     "start_time": "2021-03-30T01:32:58.755505Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert the labels to ints\n",
    "df.loc[df['labels']==b'normal.','labels']=1\n",
    "df.loc[(df['labels']!=b'normal.') & (df['labels']!=1),'labels']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-protest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:33:00.837304Z",
     "start_time": "2021-03-30T01:33:00.815074Z"
    }
   },
   "outputs": [],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-repeat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:33:16.229870Z",
     "start_time": "2021-03-30T01:33:16.165320Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-exemption",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:36:48.753386Z",
     "start_time": "2021-03-30T01:36:48.664136Z"
    }
   },
   "outputs": [],
   "source": [
    "#We will follow similar strategy as before for train test split\n",
    "X_normal = df[df['labels']==1][['duration','src_bytes','dst_bytes']].values\n",
    "X_anomalous = df[df['labels']==-1][['duration','src_bytes','dst_bytes']].values\n",
    "\n",
    "#Lets downsample the X_normal data so that we can compute quickly\n",
    "number_of_rows=10000\n",
    "ran_rows = np.random.choice(X_normal.shape[0], size=number_of_rows, replace=False, )\n",
    "X_normal = X_normal[ran_rows,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-accident",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:36:51.445586Z",
     "start_time": "2021-03-30T01:36:51.415840Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_nm_train, X_nm_test_dev = train_test_split(X_normal, train_size=0.8)\n",
    "X_nm_test, X_nm_dev = train_test_split(X_nm_test_dev, train_size=0.5)\n",
    "X_a_test, X_a_dev = train_test_split(X_anomalous, train_size=0.5)\n",
    "#Train set only has normal samples\n",
    "X_train = X_nm_train\n",
    "#Dev set has 10% of Normal samples and 50% of anomalous samples\n",
    "X_dev = np.vstack([X_nm_dev, X_a_dev])\n",
    "y_dev = np.vstack([np.full(shape=(X_nm_dev.shape[0],1), dtype='int',fill_value=1), \n",
    "                   np.full(shape=(X_a_dev.shape[0],1), dtype='int',fill_value=-1)])\n",
    "#Test set has 10% of Normal samples and 50% of anomalous samples\n",
    "X_test = np.vstack([X_nm_test, X_a_test])\n",
    "y_test = np.vstack([np.full(shape=(X_nm_test.shape[0],1),dtype='int',fill_value=1),\n",
    "                    np.full(shape=(X_a_test.shape[0],1), dtype='int',fill_value=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-catalyst",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:36:52.211400Z",
     "start_time": "2021-03-30T01:36:52.202634Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train set shape={X_train.shape}\")\n",
    "print(f\"Dev set shape={X_dev.shape}\")\n",
    "print(f\"Test set shape={X_test.shape}\")\n",
    "print(f\"Anomalies in Dev Set={np.sum(y_dev==-1)}\")\n",
    "print(f\"Anomalies in Test Set={np.sum(y_test==-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-invitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T04:28:02.711980Z",
     "start_time": "2021-03-30T04:28:02.126681Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets train isolated forest with default parameters\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-celebration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T04:28:50.610836Z",
     "start_time": "2021-03-30T04:28:50.400901Z"
    }
   },
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-ukraine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T04:37:57.221242Z",
     "start_time": "2021-03-30T04:37:57.209868Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets look at confusion matrix \n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "cm = confusion_matrix(y_dev, y_dev_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-medline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T04:29:28.767916Z",
     "start_time": "2021-03-30T04:29:28.755291Z"
    }
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-notification",
   "metadata": {},
   "source": [
    "Algorithm has decent recall on test set but very low precision. It flags a lot of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-watson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T04:33:11.188136Z",
     "start_time": "2021-03-30T04:33:07.295292Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let write a simple CV loop to find good hyper parameters for Isolation Forest\n",
    "n_estimators = [100, 200, 500, 1000]\n",
    "for n in n_estimators:\n",
    "    clf = IsolationForest(n_estimators=n)\n",
    "    clf.fit(X_train)\n",
    "    y_dev_pred = clf.predict(X_dev)\n",
    "    print(f\"n_estimaters={n}, CV score = {f1_score(y_dev, y_dev_pred, pos_label=-1):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-sapphire",
   "metadata": {},
   "source": [
    "Best estimator is with n_estimaters=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-calvin",
   "metadata": {},
   "source": [
    "### AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-passenger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T20:16:36.008162Z",
     "start_time": "2021-03-29T19:06:34.086Z"
    }
   },
   "source": [
    "### GANomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
