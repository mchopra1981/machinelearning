{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation** is a modeling technique for assessing how the statistical model will generalize to out of sample. **Cross validation** is also used to search / select model hyperparameters.\n",
    "\n",
    "There are various **Cross Validation** techniques:\n",
    "1. Holdout cross validation.\n",
    "2. k-fold cross validation.\n",
    "3. nested cross validation.\n",
    "\n",
    "#### Holdout cross validation\n",
    "**Holdout cross validation** is an algorithm where data is split randomly in test and train set. Train set is used to train the model and test set is used to assess its performance on out of sample. A common split when using the hold-out method is using 80% of data for training and the remaining 20% of the data for testing. This technique is dependent only on one test-train split that makes the results more dependent on the split.\n",
    "\n",
    "#### k-fold cross validation\n",
    "**k-fold cross validation** is an algorithm where training data is randomly divided into **k** groups of equal sizes. Then the algorithm is ran **k** times, each time one of the group is used as a validation set and rest of the groups are used as train set. After the procedure results of **k** different runs are averaged. When **k** is high the model will have low bias but high variance, when **k** is low model will have high bias but low variance. Generally choice of **5 or 10** is made. Also, when **k = N** (number of samples), its a special case called **leave one out cross validation**. It has low bias but since all the **k folds** are similar can have potentially high variance. One thing to note is in a multi-step modeling procedure cross-validation must be applied to the entire sequence of modeling steps.\n",
    "\n",
    "#### nested cross validation\n",
    "When we use **k-fold cross validation** set for both model selection and estimation of test error, that has an issue of over fitting the test set and giving overly optimistic test set error. This problem in CV is usually solved by nested cross validation. **Nested cross validation** has an inner loop nested in an outer loop. The inner loop is responsible for model selection/hyperparameter tuning (similar to validation set), while the outer loop is for error estimation (test set).\n",
    "\n",
    "Below we will demonstrate the use of the above methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets apply hold out method \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Make the sheet width 100%\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot decision regions - From Python Machine Leaning - Sebastian Raschka & Vahid Mirjalili\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50 50]\n",
      "Labels counts in y_test: [10 10 10]\n",
      "Labels counts in y_train: [30 30 30]\n",
      "Labels counts in y_validation: [10 10 10]\n"
     ]
    }
   ],
   "source": [
    "#import iris dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#load only two features\n",
    "X = iris.data[:,[2,3]]\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "#Now lets again divide train set in two to get a validation set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train_v, y_train_v, test_size=0.25, random_state=1, stratify=y_train_v)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_validation:', np.bincount(y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.97\n",
      "Validation accuracy = 0.93\n",
      "Test accuracy = 0.97\n",
      "For C=0.0001 accuracy=0.6666666666666666\n",
      "For C=0.001 accuracy=0.6666666666666666\n",
      "For C=0.01 accuracy=0.8\n",
      "For C=0.1 accuracy=0.9\n",
      "For C=1 accuracy=0.9333333333333333\n",
      "For C=2 accuracy=0.9333333333333333\n",
      "For C=5 accuracy=0.9\n",
      "For C=10 accuracy=0.9\n",
      "For C=100 accuracy=0.9\n",
      "For C=1000 accuracy=0.9\n",
      "For C=100000.0 accuracy=0.9\n",
      "Test accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "#Now we will train the data on train set and \n",
    "#will tune the regularization parameter on validation set \n",
    "#and then measure out of sample performance on test set\n",
    "\n",
    "#Lets first build a pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(random_state=1, solver='lbfgs'))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_train_pred = pipe_lr.predict(X_train)\n",
    "print(f\"Train accuracy = {pipe_lr.score(X_train, y_train):0.2}\")\n",
    "print(f\"Validation accuracy = {pipe_lr.score(X_validation, y_validation):0.2}\")\n",
    "print(f\"Test accuracy = {pipe_lr.score(X_test, y_test):0.2}\")\n",
    "\n",
    "\n",
    "param_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 5, 10, 100, 1000, 1e5]\n",
    "accuracy = dict()\n",
    "for C in param_range:\n",
    "    pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(random_state=1, solver='lbfgs', C=C))\n",
    "    pipe_lr.fit(X_train,y_train)\n",
    "    accuracy[C] = pipe_lr.score(X_validation, y_validation)\n",
    "    print(f\"For C={C} accuracy={accuracy[C]}\")\n",
    "    \n",
    "#Best accuracy if for C=1\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(random_state=1, solver='lbfgs', C=1))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_train_pred = pipe_lr.predict(X_train)\n",
    "print(f\"Test accuracy = {pipe_lr.score(X_test, y_test):0.2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, Acc : 0.917\n",
      "Fold: 1, Acc : 0.917\n",
      "Fold: 2, Acc : 1.0\n",
      "Fold: 3, Acc : 0.917\n",
      "Fold: 4, Acc : 1.0\n",
      "Fold: 5, Acc : 0.917\n",
      "Fold: 6, Acc : 0.917\n",
      "Fold: 7, Acc : 1.0\n",
      "Fold: 8, Acc : 1.0\n",
      "Fold: 9, Acc : 0.917\n",
      "Mean CV accuracy = 0.95, std = 0.041\n"
     ]
    }
   ],
   "source": [
    "#Now lets repeat the process using k-fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train_v, y_train_v)\n",
    "scores = []\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(random_state=1, solver='lbfgs', C=1))\n",
    "for k, (train , test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train_v[train], y_train_v[train])\n",
    "    score = pipe_lr.score(X_train_v[test], y_train_v[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold: {k}, Acc : {score :.3}')\n",
    "print(f'Mean CV accuracy = {np.mean(scores):.2}, std = {np.std(scores):.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.958\n",
      "{'logisticregression__C': 5}\n"
     ]
    }
   ],
   "source": [
    "#Now lets use GridSearchCV to tune the hyper parameter C\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(random_state=1, solver='lbfgs'))\n",
    "param_range = [1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 5, 10, 100, 1000, 1e5]\n",
    "param_grid = [{'logisticregression__C': param_range}]\n",
    "gs = GridSearchCV(estimator=pipe_lr, param_grid=param_grid, scoring='accuracy', cv=10, refit=True)\n",
    "gs = gs.fit(X_train_v, y_train_v)\n",
    "print(f\"Best score = {gs.best_score_:.3}\")\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train_v, y_train_v)\n",
    "print(f\"Test accuracy {clf.score(X_test, y_test):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model selected with C = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
