{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-assembly",
   "metadata": {},
   "source": [
    "## Glove vectors\n",
    "**Glove** vectors is another ML technique to learn vector representations of words. Difference between **GloVe** vectors and **word2vec** is word2vec looks at a moving window of context around a word. **Glove** vector looks at the full co-occurrence matrix. Both methods give similar results. \n",
    "\n",
    "**Glove** vector's were first proposed in the following papers\n",
    "\n",
    "https://nlp.stanford.edu/pubs/glove.pdf\n",
    "\n",
    "Below we will download pre-trained **Glove** vectors on Wikipedia corpus, and we will study some of the semantic relationships between them. **Glove** vectors can be downloaded from here https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-forwarding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T21:28:42.011892Z",
     "start_time": "2021-02-26T21:28:40.557087Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brutal-investigation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T21:28:47.177695Z",
     "start_time": "2021-02-26T21:28:42.014296Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load pre traines glove vector\n",
    "words = pd.read_table(\"./glove.6B.50d.txt\", sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-compiler",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T21:28:47.197277Z",
     "start_time": "2021-02-26T21:28:47.183103Z"
    }
   },
   "outputs": [],
   "source": [
    "#lets write a function to find closest word vector\n",
    "def cosine_similarity(A, B):\n",
    "    dot = np.dot(A,B)\n",
    "    norma = np.linalg.norm(A)\n",
    "    normb = np.linalg.norm(B)\n",
    "    cos = dot/(norma*normb)\n",
    "    return cos\n",
    "\n",
    "def get_analogy(word1, anology1, word2, embeddings):\n",
    "    group = set((word1, anology1, word2))\n",
    "    word1_emb = embeddings.loc[word1]\n",
    "    anology1_emb = embeddings.loc[anology1]\n",
    "    word2_emb = embeddings.loc[word2]\n",
    "    vec = (anology1_emb - word1_emb + word2_emb).values\n",
    "    vec = vec.reshape((1,-1))\n",
    "    dot = words.values * vec\n",
    "    norma = np.linalg.norm(vec)\n",
    "    normb = np.linalg.norm(words.values,axis=1)\n",
    "    cos_sim = np.sum(dot,axis=1)/(normb*norma)\n",
    "    top_five = words.index[np.argsort(cos_sim)[::-1][0:5]]\n",
    "    for c in top_five:\n",
    "        if c not in group:\n",
    "            return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-tomorrow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T21:28:49.731587Z",
     "start_time": "2021-02-26T21:28:47.201039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n",
      "girl\n",
      "beijing\n",
      "harbour\n",
      "route\n"
     ]
    }
   ],
   "source": [
    "print(get_analogy('man', 'king', 'woman', words))\n",
    "print(get_analogy('man', 'boy',  'woman', words))\n",
    "print(get_analogy('india', 'delhi', 'china', words))\n",
    "print(get_analogy('car', 'road', 'ship', words))\n",
    "print(get_analogy('car', 'road', 'airplane', words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-naples",
   "metadata": {},
   "source": [
    "You can see from above this simple model can predict some very interesting analogies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
